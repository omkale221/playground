{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library\n",
    "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1632617f8c744a29dc41ed1f40a8b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\train-images-idx3-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e846399fa4e19879a2288c575b0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\train-labels-idx1-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b9306055124b54affb4f45b0132ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\t10k-images-idx3-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6861f0b9fa15495b9aa342a0085eff2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to dataset/MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
    "## We create dataloader with dataset from torchvision, \n",
    "## and we dont have to download it seperately, all automatically done\n",
    "\n",
    "# Define batch size, batch size is how much data you feed for training in one iteration\n",
    "batch_size_train = 64 # We use a small batch size here for training\n",
    "batch_size_test = 1024 #\n",
    "\n",
    "# define how image transformed\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "#image datasets\n",
    "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=image_transform)\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                          train=False, \n",
    "                                          download=True,\n",
    "                                          transform=image_transform)\n",
    "#data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import matplotlib.pyplot as plt\n",
    "# We can check the dataloader\n",
    "_, (example_datas, labels) = next(enumerate(test_loader))\n",
    "sample = example_datas[0][0]\n",
    "# show the data\n",
    "plt.imshow(sample, cmap='gray', interpolation='none')\n",
    "print(\"Label: \"+ str(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "## We first import the pytorch nn module and optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## Then define the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 10\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        #dropout layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model and optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "device = \"cpu\"\n",
    "model = CNN().to(device) #using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "##define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "##define test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OM\\AppData\\Local\\Temp\\ipykernel_14676\\1895196525.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm(train_loader, total=int(len(train_loader)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f42109cd7fe4f44956da4f437e6ceab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OM\\AppData\\Local\\Temp\\ipykernel_14676\\4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3566, Accuracy: 8970/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56c48b2fe214ee0909e23053c075212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2441, Accuracy: 9259/10000 (93%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de093f234cc44cdae3c123ec667eb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1878, Accuracy: 9442/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
